In this thesis, we proposed a topic model with transformer embedding. The result has shown a better performance in returning high quality topics compared with other state-of-the-art models. Our model also demonstrates a capability in classifying substantial number of topics.

% Time-series
We also expanded the model to handle time-series data. The model was integrated with Gaussian process latent variable model, which make able the model to capture the time-series information from document set. We also expose our model has a competitive performance compared to other state of the art models.

% Limitations
In the studies though our thesis, we carried a series of experiments with varies of metrics to validate the models. Yet our model is capable to obtain a high quality topics in terms of topic coherence and topic diversity, the perplexity, in other words the predictive performance is pretty low under our testing.

% Future works
Their are more improvement to the models. First, Nonparametric Bayesian method did not consider in the research due to the time limitation. Also, since graph model and document shares similarity on power law, we expect to explore the possibility to use graph machine learning knowledge to work with the model.