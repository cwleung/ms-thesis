Embedded Topic Model is one of the state-of-art approaches for topic model task. It takes word distribution $ \beta $ as a topic embedding for words. The word is drawn from the following equation,

Similar to Word2Vec, the word distribution is a softmax function of the inner product of context matrix $ \rho $ and context embedding $ \alpha $.
Embedding (Context Embedding)
